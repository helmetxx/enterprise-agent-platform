# 需求分析智能体 (Requirements Analysis Agent) 详细设计

## 1. Dify应用配置

### 1.1 基础配置
应用名称: 需求分析智能体
类型: Assistant
模型: GPT-4
用途: A4-A5阶段需求分析和优先级排序

### 1.2 RAG配置
- 开启知识库功能
- 向量数据库: 使用Dify默认配置
- 分块大小: 600
- 重叠大小: 80
- 相似度阈值: 0.8
- 最大支持文件大小: 50MB
- 预置知识库: 产品需求规范、行业标准

## 2. 提示词模板设计

### 2.1 系统提示词
SYSTEM_PROMPT = """你是一个专业的需求分析专家。你的主要职责是分析和优先级排序产品需求。

分析要求：
1. 基于前序分析结果提取需求
2. 对需求进行分类和优先级排序
3. 评估需求的可行性和价值
4. 识别需求间的依赖关系
5. 生成结构化的需求文档

分析维度：
1. 需求类型：功能性/非功能性需求
2. 优先级：重要性和紧急性
3. 实现难度：技术和资源要求
4. 业务价值：对用户和企业的价值
5. 依赖关系：需求间的关联性

输出格式要求：
{
    "requirements_overview": {
        "total_count": "需求总数",
        "categories": {
            "functional": "功能性需求数",
            "non_functional": "非功能性需求数"
        },
        "priority_distribution": {
            "high": "高优先级数量",
            "medium": "中优先级数量",
            "low": "低优先级数量"
        }
    },
    "functional_requirements": [
        {
            "id": "需求ID",
            "title": "需求标题",
            "description": "需求描述",
            "category": "需求类别",
            "priority": {
                "importance": "重要性(1-5)",
                "urgency": "紧急性(1-5)",
                "score": "综合评分"
            },
            "implementation": {
                "difficulty": "实现难度(1-5)",
                "estimated_effort": "预估工作量(人天)",
                "technical_risks": ["风险1", "风险2"]
            },
            "business_value": {
                "user_value": "用户价值(1-5)",
                "business_value": "业务价值(1-5)",
                "roi_estimate": "投资回报评估"
            },
            "dependencies": ["依赖需求ID1", "依赖需求ID2"]
        }
    ],
    "non_functional_requirements": [
        {
            "id": "需求ID",
            "type": "性能/安全/可用性等",
            "description": "需求描述",
            "acceptance_criteria": ["验收标准1", "验收标准2"],
            "priority": "优先级(1-5)",
            "constraints": ["约束1", "约束2"]
        }
    ],
    "requirement_dependencies": {
        "dependency_graph": [
            {
                "source": "需求ID1",
                "target": "需求ID2",
                "type": "依赖类型",
                "description": "依赖说明"
            }
        ],
        "critical_path": ["关键路径需求ID列表"]
    },
    "implementation_recommendations": [
        {
            "phase": "实施阶段",
            "requirements": ["需求ID列表"],
            "rationale": "建议理由",
            "risks": ["风险1", "风险2"],
            "mitigation_strategies": ["策略1", "策略2"]
        }
    ]
}
"""

### 2.2 用户提示词模板
USER_PROMPT_TEMPLATE = """
请基于以下内容进行需求分析：

前序分析结果：
{{context}}

分析要求：
1. 提取和分类所有需求
2. 评估需求优先级
3. 分析需求依赖关系
4. 提供实施建议

请按照规定的JSON格式输出分析结果。
"""

### 2.3 跟进提示词模板
FOLLOW_UP_TEMPLATE = """
基于之前的需求分析结果，请针对以下方面进行深入分析：

关注领域：{{focus_area}}
补充信息：{{additional_context}}

请重点关注：
1. 需求优先级的调整
2. 新增需求的整合
3. 依赖关系的更新
4. 实施建议的优化

请以增量更新的方式输出分析结果。
"""

## 3. 后端集成实现

### 3.1 基础服务类
class DifyRequirementsAnalysisAgent:
    def __init__(self, api_key: str):
        self.api_base = "https://api.dify.ai/v1"
        self.api_key = api_key
        self.app_id = "your_requirements_analysis_app_id"
        
    async def analyze_requirements(self, context: Dict, previous_analysis: Optional[Dict] = None) -> Dict:
        """执行需求分析"""
        async with aiohttp.ClientSession() as session:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            messages = [
                {
                    "role": "user",
                    "content": "请分析以下需求"
                }
            ]
            
            if previous_analysis:
                messages.append({
                    "role": "assistant",
                    "content": json.dumps(previous_analysis)
                })
            
            async with session.post(
                f"{self.api_base}/chat-messages",
                headers=headers,
                json={
                    "messages": messages,
                    "query": "分析需求",
                    "context": json.dumps(context)
                }
            ) as response:
                result = await response.json()
                return json.loads(result['answer'])

### 3.2 错误处理实现
class RequirementsAnalysisError(Enum):
    ANALYSIS_FAILED = "ANALYSIS_FAILED"
    CONTEXT_INVALID = "CONTEXT_INVALID"
    API_RATE_LIMIT = "API_RATE_LIMIT"
    MODEL_ERROR = "MODEL_ERROR"
    INVALID_RESPONSE = "INVALID_RESPONSE"
    DEPENDENCY_ERROR = "DEPENDENCY_ERROR"

class RequirementsAnalysisException(Exception):
    def __init__(self, error_type: RequirementsAnalysisError, message: str, details: Optional[Dict] = None):
        self.error_type = error_type
        self.message = message
        self.details = details
        self.timestamp = datetime.utcnow()
        super().__init__(self.message)

class RequirementsAnalysisErrorHandler:
    def __init__(self):
        self.retry_configs = {
            RequirementsAnalysisError.API_RATE_LIMIT: {"max_retries": 5, "delay": 10},
            RequirementsAnalysisError.MODEL_ERROR: {"max_retries": 3, "delay": 15}
        }

    async def handle_error(self, error: RequirementsAnalysisException) -> Dict[str, Any]:
        """处理分析过程中的错误"""
        try:
            if error.error_type in self.retry_configs:
                return await self._handle_retryable_error(error)
            return await self._handle_non_retryable_error(error)
        except Exception as e:
            return {
                "status": "error",
                "error_type": str(error.error_type),
                "message": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }

### 3.3 性能优化实现
class RequirementsAnalysisOptimizer:
    def __init__(self):
        self.redis_client = Redis(host='localhost', port=6379, db=2)
        self.cache_ttl = 3600  # 1小时缓存
        
    async def optimize_analysis_process(self, context: Dict, background_tasks: BackgroundTasks) -> Dict[str, Any]:
        """优化需求分析流程"""
        
        # 1. 缓存检查
        cache_key = self._generate_cache_key(context)
        cached_result = await self._get_cached_result(cache_key)
        if cached_result:
            return cached_result
            
        # 2. 上下文处理
        processed_context = self._preprocess_context(context)
        
        # 3. 异步处理
        analysis_task = background_tasks.add_task(
            self._process_requirements,
            processed_context,
            cache_key
        )
        
        return {
            "status": "processing",
            "task_id": str(analysis_task),
            "estimated_time": self._estimate_processing_time(context)
        }

## 4. API接口定义

### 4.1 需求分析接口
@app.post("/api/requirements-analysis/analyze")
async def analyze_requirements(
    context: Dict = Body(...),
    background_tasks: BackgroundTasks = None
):
    """需求分析接口"""
    try:
        # 初始化分析优化器
        optimizer = RequirementsAnalysisOptimizer()
        
        # 异步处理需求
        result = await optimizer.optimize_analysis_process(
            context,
            background_tasks
        )
        
        return result
    except Exception as e:
        error_handler = RequirementsAnalysisErrorHandler()
        return await error_handler.handle_error(
            RequirementsAnalysisException(
                RequirementsAnalysisError.ANALYSIS_FAILED,
                str(e)
            )
        )

### 4.2 获取分析结果接口
@app.get("/api/requirements-analysis/{task_id}")
async def get_requirements_analysis(task_id: str):
    """获取需求分析结果接口"""
    try:
        optimizer = RequirementsAnalysisOptimizer()
        result = await optimizer.get_task_result(task_id)
        return result
    except Exception as e:
        error_handler = RequirementsAnalysisErrorHandler()
        return await error_handler.handle_error(
            RequirementsAnalysisException(
                RequirementsAnalysisError.ANALYSIS_FAILED,
                str(e)
            )
        )

## 5. 使用注意事项

### 5.1 输入要求
- 上下文数据格式：JSON
- 最大输入大小：1MB
- 需包含前序分析结果
- 支持增量更新

### 5.2 API调用限制
- 并发请求数：最大8个
- 调用频率：每分钟40次
- 分析超时：单次最长3分钟

### 5.3 错误处理建议
- 实现完整的错误重试机制
- 记录分析过程日志
- 支持部分失败恢复
- 提供详细错误信息

### 5.4 性能优化建议
- 使用上下文哈希缓存
- 实现增量分析机制
- 优化依赖分析算法
- 定期清理过期缓存 